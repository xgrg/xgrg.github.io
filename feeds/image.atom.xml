<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Grégory Operto - Image</title><link href="http://xgrg.github.io/" rel="alternate"></link><link href="http://xgrg.github.io/feeds/image.atom.xml" rel="self"></link><id>http://xgrg.github.io/</id><updated>2021-07-24T00:00:00+02:00</updated><entry><title>Denoising Diffusion-Weighted Imaging Data: some comparative tests</title><link href="http://xgrg.github.io/denoising-DWI/" rel="alternate"></link><published>2021-07-24T00:00:00+02:00</published><updated>2021-07-24T00:00:00+02:00</updated><author><name>Grégory Operto</name></author><id>tag:xgrg.github.io,2021-07-24:/denoising-DWI/</id><summary type="html">&lt;p&gt;We have been trying different software packages for the preprocessing of  diffusion-weighted imaging (DWI) and have been comparing their results in application to our cohort. We have focused on denoising in particular. This post is to give some brief feedback on our experience and give some details on the reasoning …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We have been trying different software packages for the preprocessing of  diffusion-weighted imaging (DWI) and have been comparing their results in application to our cohort. We have focused on denoising in particular. This post is to give some brief feedback on our experience and give some details on the reasoning that led to our final selection. Those comparative tests never intended to be a systematic analysis therefore this will unlikely make it to a paper but hopefully that might be of interest to anybody with related methodological questions. This is also an illustration of how we manage upgrades in processing pipelines &amp;mdash; for instance when some issue gets detected &amp;mdash; and how we adapt our &lt;a href="#ref4"&gt;procedures for QC&lt;/a&gt; accordingly.&lt;/p&gt;
&lt;h1&gt;The history&lt;/h1&gt;
&lt;p&gt;We began several years ago with overcomplete local PCA as described in &lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0073021"&gt;Manjón et al., 2013&lt;/a&gt;, that has been available for many years as a Matlab toolbox and gave full satisfaction. We then looked for another possible implementation that would free us from Matlab and did some tests with the &lt;a href="https://manpages.debian.org/experimental/ants/DenoiseImage.1.en.html"&gt;&lt;code&gt;DenoiseImage&lt;/code&gt;&lt;/a&gt; command provided by &lt;code&gt;ANTs&lt;/code&gt;, presented as a C++ version of the original spatially adaptive non-local means (&lt;em&gt;NLM&lt;/em&gt;) described in &lt;a href="https://pubmed.ncbi.nlm.nih.gov/20027588/"&gt;Manjón et al., 2010&lt;/a&gt;.
We opted for this tool using the Rician model, in accordance with the many references describing noise in DWI as being Rician.&lt;/p&gt;
&lt;p&gt;At some point we revised the preprocessing pipeline and added &lt;a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup"&gt;&lt;code&gt;TOPUP&lt;/code&gt;&lt;/a&gt; (see &lt;a href="https://fsl.fmrib.ox.ac.uk/fslcourse/lectures/practicals/fdt1/index.html#topup"&gt;here&lt;/a&gt; and &lt;a href="http://andysbrainblog.blogspot.com/2014/08/dti-analysis-steps-1-2-distortion.html"&gt;there&lt;/a&gt; for some help with it) for susceptibility-induced distortion correction. Since then we started observing some issues such as voxels with negative values in mean diffusivity (MD) maps, which are normally supposed to be positive. Those negative voxels mainly appeared next to the ventricles and other areas close to cerebrospinal fluid, where diffusivity is generally the highest.&lt;/p&gt;
&lt;p&gt;&lt;img alt="01" src="http://xgrg.github.io/images/dtifit/01.png"&gt;
&lt;img alt="21" src="http://xgrg.github.io/images/dtifit/21.png"&gt;
&lt;center&gt; The same DWI volume was applied denoising with &lt;code&gt;ANTs&lt;/code&gt; using Gaussian and Rician model - then the resulting MD map (Rician version) shows a significant amount (visible in the histogram) of voxels with negative values&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;After some research we finally related this to a cross effect between &lt;code&gt;TOPUP&lt;/code&gt; and &lt;code&gt;ANTs&lt;/code&gt;' denoising using the Rician model. We switched to Gaussian model and observed that negative areas disappeared from MD maps, which would since then show a more normal profile with positive values. Instead of simply changing models and closing the issue, we took this chance to extend our investigation to some other software and potentially upgrade the pipeline with some more recent techniques.&lt;/p&gt;
&lt;p&gt;In particular, the &lt;a href="https://cai2r.net/resources/denoising-using-marchenko-pastur-principal-component-analysis/"&gt;Marchenko-Pastur PCA&lt;/a&gt; &lt;a name="ref3"&gt;&lt;/a&gt;[&lt;a href="#ref3a"&gt;3&lt;/a&gt;] is regarded as a state-of-the-art technique that outperforms prior overcomplete local PCA. It has implementations in various modern packages such as &lt;a href="https://dipy.org/documentation/1.4.0./interfaces/denoise_flow/"&gt;&lt;code&gt;dipy&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://mrtrix.readthedocs.io/en/latest"&gt;&lt;code&gt;mrtrix3&lt;/code&gt;&lt;/a&gt;, therefore plugging it into any processing workflow is not that of a big concern. We quickly realized that in comparison to our previous pipelines this new type of techniques combined good performance in removing noise and preserving of anatomical details.&lt;/p&gt;
&lt;h1&gt;The data&lt;/h1&gt;
&lt;p&gt;Our DWI is acquired according to the following protocol:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2.2 mm&lt;sup&gt;3&lt;/sup&gt; isometric voxel resolution; 66 axial slices&lt;/li&gt;
&lt;li&gt;FOV 230mm&lt;/li&gt;
&lt;li&gt;TR = 9000ms&lt;/li&gt;
&lt;li&gt;TE = 90ms&lt;/li&gt;
&lt;li&gt;b-value = 1300s/m2&lt;/li&gt;
&lt;li&gt;65 directions + 8 b0 volumes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We picked ~20 random subjects and took them through the following processes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Denoising of DWI data by each technique in a selected set&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TOPUP&lt;/code&gt; based on normal and reverse-encoded B0 maps&lt;/li&gt;
&lt;li&gt;Brain extraction of the distortion-corrected averaged b=0
image (&lt;code&gt;FSL BET&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Correction for eddy currents, subject motion and susceptibility-induced
distortions using topup estimates (&lt;code&gt;FSL eddy&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;QC metric estimation derived from &lt;code&gt;TOPUP&lt;/code&gt; and &lt;code&gt;eddy&lt;/code&gt; tools (&lt;code&gt;FSL eddyQC&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Model fitting and creation of parametric maps (&lt;code&gt;FSL DTIFIT&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We repeated the process in different versions using different software:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://manpages.debian.org/experimental/ants/DenoiseImage.1.en.html"&gt;&lt;code&gt;ANTs&lt;/code&gt;&lt;/a&gt; with Rician model&lt;/li&gt;
&lt;li&gt;&lt;a href="https://manpages.debian.org/experimental/ants/DenoiseImage.1.en.html"&gt;&lt;code&gt;ANTs&lt;/code&gt;&lt;/a&gt; with Gaussian model&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.neuro.uni-jena.de/cat/"&gt;&lt;code&gt;CAT12&lt;/code&gt;&lt;/a&gt; with Gaussian model&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mrtrix.readthedocs.io/en/latest/"&gt;&lt;code&gt;mrtrix3&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dipy.org/documentation/1.4.0./interfaces/denoise_flow/"&gt;&lt;code&gt;dipy&lt;/code&gt;&lt;/a&gt; (&lt;a href="https://dipy.org/documentation/1.0.0./examples_built/denoise_localpca/"&gt;&lt;em&gt;LPCA&lt;/em&gt;&lt;/a&gt;, &lt;a href="https://dipy.org/documentation/1.0.0./examples_built/denoise_mppca/"&gt;&lt;em&gt;MPPCA&lt;/em&gt;&lt;/a&gt;, &lt;a href="https://dipy.org/documentation/1.4.1./examples_built/denoise_nlmeans/"&gt;&lt;em&gt;NLM&lt;/em&gt;&lt;/a&gt;, &lt;a href="https://dipy.org/documentation/1.4.0./examples_built/denoise_patch2self/"&gt;&lt;em&gt;Patch2Self&lt;/em&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;No denoising&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;The results&lt;/h1&gt;
&lt;p&gt;A general observation is that NLM is good at removing noise but also yields noticeably smoother resulting images. In comparison MPPCA preserves anatomical details although some noise is still visible.&lt;/p&gt;
&lt;p&gt;&lt;img alt="04" src="http://xgrg.github.io/images/dtifit/04.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="16" src="http://xgrg.github.io/images/dtifit/16.png"&gt;&lt;/p&gt;
&lt;p&gt;Looking at residual maps confirms that observation as less anatomical traits can be identified using MPPCA (on the right).&lt;/p&gt;
&lt;p&gt;&lt;img alt="18" src="http://xgrg.github.io/images/dtifit/18.png"&gt;&lt;/p&gt;
&lt;p&gt;Same observations with FA maps and RGB tensors obtained from NLM-denoised data which looked quite smoother than using MPPCA denoising.&lt;/p&gt;
&lt;p&gt;&lt;img alt="19" src="http://xgrg.github.io/images/dtifit/19.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="02" src="http://xgrg.github.io/images/dtifit/02.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="06" src="http://xgrg.github.io/images/dtifit/06.png"&gt;&lt;/p&gt;
&lt;p&gt;One big concern of ours was to make sure resulting MD maps would not include large areas with negative voxels. In that respect, NLM with Gaussian model (orange) systematically gave the lowest number of negative voxels and the minimum value closest to zero, compared to NLM with Rician model (blue) and MPPCA (green).&lt;/p&gt;
&lt;p&gt;&lt;img alt="12" src="http://xgrg.github.io/images/dtifit/12.png"&gt;&lt;/p&gt;
&lt;p&gt;In the end NLM with Rician model (orange) was the only method yielding so many negative voxels in MD.&lt;/p&gt;
&lt;p&gt;&lt;img alt="15" src="http://xgrg.github.io/images/dtifit/15.png"&gt;&lt;/p&gt;
&lt;p&gt;More techniques: same observation.&lt;/p&gt;
&lt;p&gt;&lt;img alt="22" src="http://xgrg.github.io/images/dtifit/22.png"&gt;&lt;/p&gt;
&lt;p&gt;We also made sure that those large initial periventricular negative areas disappeared from the final MD maps.&lt;/p&gt;
&lt;p&gt;&lt;img alt="20" src="http://xgrg.github.io/images/dtifit/20.png"&gt;&lt;/p&gt;
&lt;p&gt;Signal-to-noise/carrier-to-noise ratios (SNR/CNR) is also found higher using MPPCA (or CAT12) than using NLM with ANTs Rician and Gaussian (blue and orange respectively).&lt;/p&gt;
&lt;p&gt;&lt;img alt="17" src="http://xgrg.github.io/images/dtifit/17.png"&gt;&lt;/p&gt;
&lt;p&gt;Finally we looked at the estimation of outlier slices in each processed volume, as provided by &lt;a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddyqc/UsersGuide"&gt;&lt;code&gt;eddyQC&lt;/code&gt;&lt;/a&gt; to realize that using anything but NLM-Rician improves that QC metric. To some extent NLM-Gaussian could be considered a winner in this test but it might be thought as a logical consequence of the smoother aspect of the resulting images. Less outliers but less anatomical details as well.&lt;/p&gt;
&lt;p&gt;&lt;img alt="23" src="http://xgrg.github.io/images/dtifit/23.png"&gt;&lt;/p&gt;
&lt;p&gt;Concatenate both normal and reverse-encoded volumes&lt;/p&gt;
&lt;h1&gt;The conclusion (current pipeline)&lt;/h1&gt;
&lt;p&gt;Some modern, mature, maintained and easy-to-plug implementations are now available for denoising of DWI. This includes at least packages such as &lt;a href="https://dipy.org/documentation/1.4.0./interfaces/denoise_flow/"&gt;&lt;code&gt;dipy&lt;/code&gt;&lt;/a&gt;  or &lt;a href="https://mrtrix.readthedocs.io/en/latest/"&gt;&lt;code&gt;mrtrix3&lt;/code&gt;&lt;/a&gt;. In application to our tests they both yielded good results based on QC metrics and visual inspection. Those were primarily designed for DWI, contrary to denoising based on NLM as done in other toolboxes (&lt;code&gt;CAT12&lt;/code&gt;, &lt;code&gt;ANTs&lt;/code&gt;) which are mainly oriented towards T1.&lt;/p&gt;
&lt;p&gt;We finally selected the following pipeline and implemented a set of systematic checks for quality control, based on validators (as described in  &lt;a name="ref4"&gt;&lt;/a&gt;&lt;a href="#ref4a"&gt;4&lt;/a&gt;).&lt;/p&gt;
&lt;div style="padding:20px; text-align:justify; background-color:#50453e; color:white"&gt;

 &lt;li&gt;Denoising of the resulting volume using &lt;code&gt;mrtrix&lt;/code&gt; &lt;i&gt;MPPCA&lt;/i&gt;&lt;/li&gt;
 &lt;li&gt;&lt;code&gt;TOPUP&lt;/code&gt; based on the normal and reverse-encoded B0 maps&lt;/li&gt;
 &lt;li&gt;Brain extraction of the distortion-corrected averaged b=0 image (&lt;code&gt;FSL BET&lt;/code&gt;)&lt;/li&gt;
 &lt;li&gt;Correct for eddy currents, subject motion and susceptibility-induced distortions using topup estimates (&lt;a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy"&gt;&lt;code&gt;FSL eddy&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
 &lt;li&gt;Compute QC metrics derived from &lt;code&gt;TOPUP&lt;/code&gt; and &lt;code&gt;eddy&lt;/code&gt; tools (&lt;a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddyqc/UsersGuide"&gt;&lt;code&gt;FSL eddyQC&lt;/code&gt;&lt;/a&gt;)).&lt;/li&gt;
 &lt;li&gt;Fit diffusion tensor models and generate parametric maps (&lt;code&gt;FSL DTIFIT&lt;/code&gt;)&lt;/li&gt;
 &lt;li&gt;Compute radial diffusivity map (using &lt;code&gt;FSL fslmaths&lt;/code&gt;)&lt;/li&gt;

&lt;/div&gt;

&lt;p&gt;Steps for automatic QC (&lt;a href="https://gitlab.com/bbrc/xnat/bbrc-validator"&gt;&lt;code&gt;bbrc-validator&lt;/code&gt;&lt;/a&gt;):&lt;/p&gt;
&lt;div style="padding:20px; text-align:justify; background-color:#50453e; color:white"&gt;

&lt;li&gt;Count negative voxels and check that they are under a certain limit.
&lt;a href="https://gitlab.com/bbrc/xnat/bbrc-validator/-/blob/master/bbrc/validation/processing/dtifit.py#L354"&gt;&lt;code&gt;DTIFITValidator.HasFewNegativeVoxelsInMD&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Measure SNR/CNR using &lt;a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddyqc/UsersGuide"&gt;&lt;code&gt;eddyqc&lt;/code&gt;&lt;/a&gt; and check that they are within a certain range &lt;a href="https://gitlab.com/bbrc/xnat/bbrc-validator/-/blob/master/bbrc/validation/processing/dtifit.py#L405"&gt;&lt;code&gt;DTIFITValidator.HasAcceptableAverageSNR&lt;/code&gt;&lt;/a&gt; &lt;a href="https://gitlab.com/bbrc/xnat/bbrc-validator/-/blob/master/bbrc/validation/processing/dtifit.py#L438"&gt;&lt;code&gt;DTIFITValidator.HasAcceptableAverageCNR&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Check that the total percentage of outlier slices in the volume (as detected by &lt;code&gt;eddy&lt;/code&gt;) is under 1% &lt;a href="https://gitlab.com/bbrc/xnat/bbrc-validator/-/blob/master/bbrc/validation/processing/dtifit.py#L461"&gt;&lt;code&gt;DTIFITValidator.HasAcceptableOutliersPercentage&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;

&lt;/div&gt;

&lt;p&gt;These checks will systematically be performed on any new execution of the DWI processing pipeline. Resulting validators now include the following additional entries, to prevent from any future regression.&lt;/p&gt;
&lt;p&gt;&lt;img alt="03" src="http://xgrg.github.io/images/dtifit/03.png"&gt;
&lt;center&gt;
(obtained using the command &lt;code&gt;&lt;a href="https://gitlab.com/xgrg/bx"&gt;bx&lt;/a&gt; dtifit report BBRC_E00045&lt;/code&gt;)&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Huge kudos and most credits to Jordi Huguet (&lt;a href="http://barcelonabeta.org"&gt;Barcelonaβeta Brain Research Center&lt;/a&gt;) who took all the burden of running these tests with those different techniques, extracting metrics for comparison and analyzing them. All the figures in this post are attributed to his work.&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;1.&lt;a href="#ref1"&gt;↑&lt;/a&gt; &lt;a name="ref1a"&gt;&lt;/a&gt;
 &lt;em&gt;J. Manjón, P. Coupé, L. Concha, A. Buades, L. Collins, M. Robles,&lt;/em&gt;  &lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0073021"&gt;Diffusion Weighted Image Denoising Using Overcomplete Local PCA&lt;/a&gt;, PLOS One (2013)&lt;/p&gt;
&lt;p&gt;2.&lt;a href="#ref2"&gt;↑&lt;/a&gt; &lt;a name="ref2a"&gt;&lt;/a&gt; &lt;em&gt;P. Coupe, J. Manjon, M. Robles, L. Collins&lt;/em&gt;, &lt;a href="https://hal.archives-ouvertes.fr/hal-00645538/document"&gt;Adaptive Multiresolution Non-Local Means Filter for 3D MR Image Denoising&lt;/a&gt;, IET Image Processing, Institution of Engineering and Technology (2011)&lt;/p&gt;
&lt;p&gt;3.&lt;a href="#ref3"&gt;↑&lt;/a&gt; &lt;a name="ref3a"&gt;&lt;/a&gt; &lt;em&gt;J. Veraart J, DS. Novikov, D. Christiaens, B. Ades-Aron, J. Sijbers, E. Fieremans&lt;/em&gt;,
&lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811916303949"&gt;Denoising of diffusion MRI using random matrix theory&lt;/a&gt;
Neuroimage (2016)&lt;/p&gt;
&lt;p&gt;4.&lt;a href="#ref4"&gt;↑&lt;/a&gt; &lt;a name="ref4a"&gt;&lt;/a&gt; &lt;em&gt;J. Huguet, C. Falcon, D. Fusté, S. Girona, D. Vicente, JL Molinuevo, JD Gispert, G. Operto for the ALFA Study&lt;/em&gt;,
&lt;a href="https://www.frontiersin.org/articles/10.3389/fnins.2021.633438/full"&gt;Management and Quality Control of Large Neuroimaging Datasets: Developments From the Barcelonaβeta Brain Research Center&lt;/a&gt;, Front. in Neurosc. (2021)&lt;/p&gt;</content><category term="Image"></category><category term="imaging"></category></entry><entry><title>ROI-based analysis in neuroimaging: a walkthrough in Python</title><link href="http://xgrg.github.io/regions-of-interest/" rel="alternate"></link><published>2020-02-03T00:00:00+01:00</published><updated>2020-02-03T00:00:00+01:00</updated><author><name>Grégory Operto</name></author><id>tag:xgrg.github.io,2020-02-03:/regions-of-interest/</id><summary type="html">&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;Analyses based on Regions-of-Interest (ROIs) focus
 on a number of parcels with homogeneous characteristics, which are generally
 related to brain structures. This type of analysis is rather popular in neuroimaging
 especially when the study builds onto some hypothesis precisely related to
 some of these brain structures.&lt;/p&gt;
&lt;p&gt;Two approaches are generally …&lt;/p&gt;</summary><content type="html">&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;Analyses based on Regions-of-Interest (ROIs) focus
 on a number of parcels with homogeneous characteristics, which are generally
 related to brain structures. This type of analysis is rather popular in neuroimaging
 especially when the study builds onto some hypothesis precisely related to
 some of these brain structures.&lt;/p&gt;
&lt;p&gt;Two approaches are generally available, as two opposite ways of addressing anatomical variability.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One way consists in warping all the subjects to a common
reference space and using ROIs defined from a brain atlas.&lt;/li&gt;
&lt;li&gt;The other one consists in delineating ROIs individually in every subject,
  e.g., using segmentation algorithms.  Resulting objects are likely to be closer
  to the individual anatomical truth, therefore improving sensitivity by focusing on
  the signal of interest, as compared to voxel-based methods.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ROIs are thus often defined over anatomical data and then used to filter the
 signal from other image modalities.&lt;/p&gt;
&lt;h2&gt;TL;DR&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;div style="padding:20px; text-align:justify; background-color:#222222"&gt;
This post describes a basic end-to-end analysis workflow based on
regions-of-interest using simulated data. It relies on typical operations
e.g. extracting values, merging them with covariates, plotting, performing some
linear regressions or group comparisons, which have been turned to Python code
in a package called &lt;a href="https://github.com/xgrg/roistats"&gt;roistats&lt;/a&gt;. &lt;/div&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Collecting mean values from atlas regions&lt;/h2&gt;
&lt;p&gt;In this example, we generate some maps (N=50) with some random values over an
MNI brain mask. They will be like our individual (subject-level) maps.  &lt;/p&gt;
&lt;p&gt;Regions-of-interest will be defined over these simulated maps and descriptive values will be
extracted from these regions. Real images may be used instead (provided they
  are in the same reference space).&lt;/p&gt;
&lt;h4&gt;Generating random maps (optional)&lt;/h4&gt;
&lt;p&gt;This &lt;a href="https://gist.github.com/xgrg/3405bbe95f6aa589ac5dfbfb9843c73f"&gt;gist&lt;/a&gt;
shows the documented execution of this part.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nilearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nilearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="n"&gt;atlas&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_mni152_brain_mask&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# Generate 50 random maps&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;atlas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dataobj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;atlas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dataobj&lt;/span&gt;
    &lt;span class="n"&gt;im&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new_img_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;atlas&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;im&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;smooth_img&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;im&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mkstemp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suffix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.nii.gz&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;im&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_filename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nilearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;plotting&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;npl&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cort-maxprob-thr50-2mm&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;atlas_fp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetch_atlas_harvard_oxford&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;maps&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="n"&gt;npl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot_roi&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;atlas_fp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bg_img&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="example_plot_roi1" src="/images/roi/roi_plot1.png"&gt;
&lt;img alt="example_plot_roi2" src="/images/roi/roi_plot2.png"&gt;
&lt;img alt="example_plot_roi3" src="/images/roi/roi_plot3.png"&gt;&lt;/p&gt;
&lt;h4&gt;Collecting the ROI values&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;roistats.collect&lt;/code&gt; module has a function &lt;code&gt;roistats_from_maps(images, atlas_fp)&lt;/code&gt;
which takes a set (&lt;code&gt;images&lt;/code&gt;) of images (their file paths) and &lt;code&gt;atlas_fp&lt;/code&gt;, the
 path to a &lt;em&gt;ROI volume&lt;/em&gt; (i.e. a volume with integer labels defining areas of
   interest [and 0 elsewhere]). All images should be coregistered in the same
   space (e.g. MNI). The ROI volume may thus come from an atlas, as the ones
   from the &lt;a href="https://nilearn.github.io/modules/reference.html#module-nilearn.datasets"&gt;&lt;code&gt;nilearn.datasets&lt;/code&gt;&lt;/a&gt;
  module.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;roistats&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;collect&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# Here we collect the mean value from each ROI on every image&lt;/span&gt;
&lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;collect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;roistats_from_maps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;atlas_fp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="n"&gt;subjects&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The created table will have as many columns as there are ROI labels.
We may rename them with the corresponding names from the atlas.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Get label names from Harvard Oxford atlas&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nilearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;

&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cort-maxprob-thr50-2mm&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetch_atlas_harvard_oxford&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;labels&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Store them in a dict&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Background&lt;/th&gt;
&lt;th&gt;Frontal Pole&lt;/th&gt;
&lt;th&gt;Insular Cortex&lt;/th&gt;
&lt;th&gt;Superior Frontal Gyrus&lt;/th&gt;
&lt;th&gt;Middle Frontal Gyrus&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;subject&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;/tmp/tmp_9rh_8p3.nii.gz&lt;/td&gt;
&lt;td&gt;0.10316&lt;/td&gt;
&lt;td&gt;0.465694&lt;/td&gt;
&lt;td&gt;0.503227&lt;/td&gt;
&lt;td&gt;0.495352&lt;/td&gt;
&lt;td&gt;0.475365&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;/tmp/tmpqht6np22.nii.gz&lt;/td&gt;
&lt;td&gt;0.103357&lt;/td&gt;
&lt;td&gt;0.471021&lt;/td&gt;
&lt;td&gt;0.498914&lt;/td&gt;
&lt;td&gt;0.488398&lt;/td&gt;
&lt;td&gt;0.478122&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;/tmp/tmpk0117ahy.nii.gz&lt;/td&gt;
&lt;td&gt;0.103379&lt;/td&gt;
&lt;td&gt;0.470353&lt;/td&gt;
&lt;td&gt;0.497508&lt;/td&gt;
&lt;td&gt;0.494957&lt;/td&gt;
&lt;td&gt;0.490264&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;/tmp/tmpq6pnpx0r.nii.gz&lt;/td&gt;
&lt;td&gt;0.103438&lt;/td&gt;
&lt;td&gt;0.46967&lt;/td&gt;
&lt;td&gt;0.507529&lt;/td&gt;
&lt;td&gt;0.49202&lt;/td&gt;
&lt;td&gt;0.47704&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;/tmp/tmpm2un1_ri.nii.gz&lt;/td&gt;
&lt;td&gt;0.103383&lt;/td&gt;
&lt;td&gt;0.471193&lt;/td&gt;
&lt;td&gt;0.501927&lt;/td&gt;
&lt;td&gt;0.491835&lt;/td&gt;
&lt;td&gt;0.474059&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Plotting the data&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;roistats&lt;/code&gt; comes with a module &lt;code&gt;plotting&lt;/code&gt; intended for visualizing tabular data
(built on top of &lt;a href="https://seaborn.pydata.org/"&gt;&lt;code&gt;seaborn&lt;/code&gt;&lt;/a&gt;/&lt;a href="https://matplotlib.org/"&gt;&lt;code&gt;matplotlib&lt;/code&gt;&lt;/a&gt;)
with some predefined functions for boxplots, scatter plots with linear model fits
or histograms, with the possibility to account for covariates (using
  inline linear regressions). The same function hence takes the data, computes
  some version corrected for given covariates and plots it in some different possible
  ways.&lt;/p&gt;
&lt;p&gt;To recreate some kind of realistic case, let us add some totally random
covariates to these previously extracted ROI values. Random "group", random age,
random sex,
random &lt;a href="https://en.wikipedia.org/wiki/Apolipoprotein_E"&gt;APOE&lt;/a&gt; E4 status.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Let us add some totally random covariates&lt;/span&gt;

&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;male&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;female&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;apoee4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;HO&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;HT&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;NC&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;index&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;

&lt;span class="c1"&gt;# How do they look&lt;/span&gt;
&lt;span class="n"&gt;covariates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;apoee4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;covariates&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;group&lt;/th&gt;
&lt;th&gt;age&lt;/th&gt;
&lt;th&gt;sex&lt;/th&gt;
&lt;th&gt;apoee4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;53.620190&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;td&gt;NC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;53.531222&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;td&gt;NC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;51.073742&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;td&gt;NC&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;54.184375&lt;/td&gt;
&lt;td&gt;male&lt;/td&gt;
&lt;td&gt;HT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;52.552064&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;td&gt;HT&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We will now plot the mean values from any given region (say the &lt;a href="https://en.wikipedia.org/w/index.php?title=Temporal_pole"&gt;temporal pole&lt;/a&gt; but could be any other one). Importantly, we
want to account for the potential influence of the covariates we just added (e.g.
  differences between men/women, effect of age, influence of APOE status).&lt;/p&gt;
&lt;p&gt;For instance, let us look at the effect of the APOE status on the mean intensities
taken in the Temporal Pole (across these 50 maps), accounting for the effect of age,
sex and "group".&lt;/p&gt;
&lt;p&gt;&lt;code&gt;plotting&lt;/code&gt; has a method called &lt;code&gt;boxplot&lt;/code&gt; for this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;roistats&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;plotting&lt;/span&gt;
&lt;span class="n"&gt;region&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Temporal Pole&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# Plot data from this region&lt;/span&gt;
&lt;span class="c1"&gt;# Do it *accounting for covariates*&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boxplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;region&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;apoee4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="n"&gt;covariates&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;default&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="boxplot1" src="/images/roi/boxplot1.png"&gt;&lt;/p&gt;
&lt;p&gt;The plot displays the p values of two-sample t tests between each pair of
categories, here APOE groups. No significant difference is found in any case
(which makes sense considering the data comes from the same random process).&lt;/p&gt;
&lt;p&gt;Same thing now with sex differences.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Now by sex&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;boxplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;region&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="n"&gt;covariates&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                     &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;default&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="boxplot2" src="/images/roi/boxplot2.png"&gt;&lt;/p&gt;
&lt;p&gt;Still no significant difference.&lt;/p&gt;
&lt;p&gt;Let us now look at age x APOE interaction, corrected for sex and "group".&lt;/p&gt;
&lt;p&gt;&lt;code&gt;plotting&lt;/code&gt; has a method called &lt;code&gt;lmplot&lt;/code&gt; for this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lmplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;region&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;covariates&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;group&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                    &lt;span class="n"&gt;hue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;apoee4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;default&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="lmplot" src="/images/roi/lmplot.png"&gt;&lt;/p&gt;
&lt;p&gt;For the last example, the table needs to be reshaped a bit ("unpivot"). This is
done to allow the use of large tables with many rows (and a moderate number of columns).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# For this last one reshape the table a bit (&amp;quot;unpivot&amp;quot;)&lt;/span&gt;
&lt;span class="n"&gt;cov&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;apoee4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;melt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;melt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id_vars&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;index&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;value_vars&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
               &lt;span class="n"&gt;var_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;region&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_index&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;index&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;melt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;melt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cov&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It would look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Only keep 5 regions for this example&lt;/span&gt;
&lt;span class="n"&gt;regions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;melt&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;region&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="n"&gt;melt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;melt&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;melt&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;region&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;regions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;

&lt;span class="c1"&gt;# It looks like this&lt;/span&gt;
&lt;span class="n"&gt;melt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;region&lt;/th&gt;
&lt;th&gt;value&lt;/th&gt;
&lt;th&gt;age&lt;/th&gt;
&lt;th&gt;apoee4&lt;/th&gt;
&lt;th&gt;sex&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Inferior Frontal Gyrus, pars triangularis&lt;/td&gt;
&lt;td&gt;0.458292&lt;/td&gt;
&lt;td&gt;53.62019&lt;/td&gt;
&lt;td&gt;NC&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Superior Parietal Lobule&lt;/td&gt;
&lt;td&gt;0.508143&lt;/td&gt;
&lt;td&gt;53.62019&lt;/td&gt;
&lt;td&gt;NC&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Frontal Orbital Cortex&lt;/td&gt;
&lt;td&gt;0.480872&lt;/td&gt;
&lt;td&gt;53.62019&lt;/td&gt;
&lt;td&gt;NC&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Central Opercular Cortex&lt;/td&gt;
&lt;td&gt;0.496808&lt;/td&gt;
&lt;td&gt;53.62019&lt;/td&gt;
&lt;td&gt;NC&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Supracalcarine Cortex&lt;/td&gt;
&lt;td&gt;0.487534&lt;/td&gt;
&lt;td&gt;53.62019&lt;/td&gt;
&lt;td&gt;NC&lt;/td&gt;
&lt;td&gt;female&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;code&gt;roistats.plotting&lt;/code&gt; has a method called &lt;code&gt;hist&lt;/code&gt; to represent all the ROIs on a
single plot.&lt;/p&gt;
&lt;p&gt;In this example, APOE status would be considered as the effect of interest,
and age and sex as covariates.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;melt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;apoee4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;region_colname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;region&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;covariates&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                  &lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.55&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                  &lt;span class="n"&gt;aspect&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;default&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="hist1" src="/images/roi/hist1.png"&gt;&lt;/p&gt;
&lt;p&gt;Now same thing with sex differences, correcting for age and APOE status.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Again by sex&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plotting&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;melt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;region_colname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;region&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;covariates&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;apoee4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                  &lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.45&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.55&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                  &lt;span class="n"&gt;aspect&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;palette&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;default&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="hist2" src="/images/roi/hist2.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;roistats&lt;/code&gt; can be found at this &lt;a href="https://github.com/xgrg/roistats"&gt;URL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the context, I was working with diffusion-weighted imaging and myelin content
to study the effect of age, sex and the APOE gene on microstructural properties
of the white matter when I started to write this code.&lt;/p&gt;
&lt;p&gt;This led to these two publications:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;G. Operto, J.L. Molinuevo, R. Cacciaglia, C. Falcón, A. Brugulat-Serrat,
M. Suárez-Calvet, O. Grau-Rivera, N. Bargalló, S. Morán, M. Esteller,
J.D. Gispert for the ALFA Study, &lt;a href="https://www.sciencedirect.com/science/article/pii/S221315821930333X"&gt;Interactive effect of age and APOE-ε4 allele load on white matter myelin content in cognitively normal middle-aged subjects&lt;/a&gt;, Neuroimage: Clinical, 2019&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;G. Operto, R. Cacciaglia, O. Grau-Rivera, C. Falcon, A. Brugulat-Serrat,
P. Ródenas, R. Ramos, S. Morán, M. Esteller, N. Bargalló, J.L. Molinuevo,
J.D. Gispert for the ALFA Study, &lt;a href="https://alzres.biomedcentral.com/articles/10.1186/s13195-018-0375-x"&gt;White matter microstructure is altered in
cognitively normal middle-aged APOE-ε4 homozygotes&lt;/a&gt;
, Alzheimer’s Research &amp;amp; Therapy, 2018&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disclaimer: to date &lt;a href="https://github.com/xgrg/roistats"&gt;&lt;code&gt;roistats&lt;/code&gt;&lt;/a&gt; is only
available as a raw (probably dirty) code but please open an issue if
making it available on package repositories may be useful to you and I
will make the effort.&lt;/p&gt;</content><category term="Image"></category><category term="image"></category><category term="python"></category></entry></feed>